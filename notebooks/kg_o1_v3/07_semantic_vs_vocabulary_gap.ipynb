{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 07: Semantic vs Vocabulary Gap Analysis\n",
    "\n",
    "## Objective\n",
    "\n",
    "Quantify the capability difference between:\n",
    "- **v2 Vocabulary QA**: Entity resolution via search (95.2% EM)\n",
    "- **v3 Semantic QA**: Multi-hop reasoning via graph traversal\n",
    "\n",
    "## Key Questions\n",
    "\n",
    "1. Does KRAKEN have true semantic reasoning capability?\n",
    "2. What types of questions can each approach answer?\n",
    "3. When should you use search vs graph traversal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T01:08:40.325826Z",
     "iopub.status.busy": "2026-01-22T01:08:40.325397Z",
     "iopub.status.idle": "2026-01-22T01:08:40.606838Z",
     "shell.execute_reply": "2026-01-22T01:08:40.606056Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v3 output directory: /home/trentleslie/Insync/projects/biomapper2/notebooks/kg_o1_v3/outputs\n",
      "v2 output directory: /home/trentleslie/Insync/projects/biomapper2/notebooks/kg_o1_v2/outputs\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Add project root to path\n",
    "PROJECT_ROOT = Path.cwd().parents[1]\n",
    "sys.path.insert(0, str(PROJECT_ROOT / 'src'))\n",
    "sys.path.insert(0, str(Path.cwd()))\n",
    "\n",
    "# Import utilities\n",
    "from kg_o1_v3_utils import save_json, load_json\n",
    "\n",
    "# Output directory\n",
    "OUTPUT_DIR = Path.cwd() / 'outputs'\n",
    "V2_OUTPUT_DIR = Path.cwd().parent / 'kg_o1_v2' / 'outputs'\n",
    "\n",
    "print(f\"v3 output directory: {OUTPUT_DIR}\")\n",
    "print(f\"v2 output directory: {V2_OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load All Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T01:08:40.623861Z",
     "iopub.status.busy": "2026-01-22T01:08:40.623690Z",
     "iopub.status.idle": "2026-01-22T01:08:40.653851Z",
     "shell.execute_reply": "2026-01-22T01:08:40.653416Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded API audit: GO/NO-GO = GO\n",
      "Loaded predicate mapping: 88 predicates\n",
      "Loaded subgraphs: 20 subgraphs\n",
      "Loaded paths: 3 paths found\n",
      "Loaded QA dataset: 3359 QA pairs\n",
      "Loaded evaluation results\n"
     ]
    }
   ],
   "source": [
    "# Load v3 results\n",
    "v3_results = {}\n",
    "\n",
    "# NB01: API Audit\n",
    "if (OUTPUT_DIR / 'one_hop_api_audit.json').exists():\n",
    "    v3_results['api_audit'] = load_json(OUTPUT_DIR / 'one_hop_api_audit.json')\n",
    "    print(f\"Loaded API audit: GO/NO-GO = {v3_results['api_audit'].get('go_no_go_decision', {}).get('decision')}\")\n",
    "\n",
    "# NB02: Predicate mapping\n",
    "if (OUTPUT_DIR / 'predicate_mapping.json').exists():\n",
    "    v3_results['predicate_mapping'] = load_json(OUTPUT_DIR / 'predicate_mapping.json')\n",
    "    print(f\"Loaded predicate mapping: {v3_results['predicate_mapping'].get('summary', {}).get('total_predicates', 0)} predicates\")\n",
    "\n",
    "# NB03: Semantic subgraphs\n",
    "if (OUTPUT_DIR / 'semantic_subgraphs.json').exists():\n",
    "    v3_results['subgraphs'] = load_json(OUTPUT_DIR / 'semantic_subgraphs.json')\n",
    "    print(f\"Loaded subgraphs: {len(v3_results['subgraphs'].get('subgraphs', []))} subgraphs\")\n",
    "\n",
    "# NB04: Multi-hop paths\n",
    "if (OUTPUT_DIR / 'multi_hop_paths.json').exists():\n",
    "    v3_results['paths'] = load_json(OUTPUT_DIR / 'multi_hop_paths.json')\n",
    "    print(f\"Loaded paths: {v3_results['paths'].get('summary', {}).get('paths_found', 0)} paths found\")\n",
    "\n",
    "# NB05: Semantic QA dataset\n",
    "if (OUTPUT_DIR / 'semantic_qa_dataset.json').exists():\n",
    "    v3_results['qa_dataset'] = load_json(OUTPUT_DIR / 'semantic_qa_dataset.json')\n",
    "    print(f\"Loaded QA dataset: {len(v3_results['qa_dataset'].get('qa_pairs', []))} QA pairs\")\n",
    "\n",
    "# NB06: Evaluation results\n",
    "if (OUTPUT_DIR / 'semantic_qa_evaluation.json').exists():\n",
    "    v3_results['evaluation'] = load_json(OUTPUT_DIR / 'semantic_qa_evaluation.json')\n",
    "    print(f\"Loaded evaluation results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T01:08:40.655077Z",
     "iopub.status.busy": "2026-01-22T01:08:40.654985Z",
     "iopub.status.idle": "2026-01-22T01:08:40.657615Z",
     "shell.execute_reply": "2026-01-22T01:08:40.657183Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load v2 results for comparison\n",
    "v2_results = {}\n",
    "\n",
    "if V2_OUTPUT_DIR.exists():\n",
    "    # v2 search evaluation\n",
    "    if (V2_OUTPUT_DIR / 'search_evaluation_results.json').exists():\n",
    "        v2_results['evaluation'] = load_json(V2_OUTPUT_DIR / 'search_evaluation_results.json')\n",
    "        print(f\"Loaded v2 evaluation results\")\n",
    "    \n",
    "    # v2 QA dataset\n",
    "    if (V2_OUTPUT_DIR / 'multihop_qa_dataset.json').exists():\n",
    "        v2_results['qa_dataset'] = load_json(V2_OUTPUT_DIR / 'multihop_qa_dataset.json')\n",
    "        print(f\"Loaded v2 QA dataset\")\n",
    "else:\n",
    "    print(\"v2 results not available - using reference values\")\n",
    "    v2_results = {\n",
    "        'reference': {\n",
    "            'vocabulary_qa_em': 0.952,  # From v2 final report\n",
    "            'hybrid_search_em': 0.952,\n",
    "            'text_search_em': 1.0,\n",
    "            'vector_search_em': 0.0,\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Capability Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T01:08:40.658770Z",
     "iopub.status.busy": "2026-01-22T01:08:40.658680Z",
     "iopub.status.idle": "2026-01-22T01:08:40.682627Z",
     "shell.execute_reply": "2026-01-22T01:08:40.681917Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CAPABILITY COMPARISON: v2 vs v3\n",
      "============================================================\n",
      "\n",
      "Vocabulary QA (v2):\n",
      "  Method: hybrid_search + reranking\n",
      "  Exact Match: 95.2%\n",
      "  Use case: Entity resolution (same entity, different IDs)\n",
      "  Example: What HMDB ID corresponds to glucose?\n",
      "\n",
      "Semantic QA (v3):\n",
      "  Search EM: 0.0%\n",
      "  Graph Recall: 63.2%\n",
      "  Use case: Multi-hop reasoning (different entities, semantic relations)\n",
      "  Example: What pathway does glucose participate in?\n"
     ]
    }
   ],
   "source": [
    "# Build capability comparison\n",
    "print(\"=\"*60)\n",
    "print(\"CAPABILITY COMPARISON: v2 vs v3\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# v2 metrics\n",
    "v2_vocab_em = v2_results.get('reference', {}).get('vocabulary_qa_em', 0.952)\n",
    "if 'evaluation' in v2_results:\n",
    "    v2_vocab_em = v2_results['evaluation'].get('summary', {}).get('overall_metrics', {}).get('hybrid_em', v2_vocab_em)\n",
    "\n",
    "# v3 metrics\n",
    "v3_search_em = 0\n",
    "v3_graph_recall = 0\n",
    "\n",
    "if 'evaluation' in v3_results:\n",
    "    v3_search_em = v3_results['evaluation'].get('search_method', {}).get('metrics', {}).get('exact_match', 0)\n",
    "    v3_graph_recall = v3_results['evaluation'].get('graph_method', {}).get('metrics', {}).get('recall', 0)\n",
    "\n",
    "comparison = {\n",
    "    'v2_vocabulary_qa': {\n",
    "        'method': 'hybrid_search + reranking',\n",
    "        'exact_match': v2_vocab_em,\n",
    "        'use_case': 'Entity resolution (same entity, different IDs)',\n",
    "        'example': 'What HMDB ID corresponds to glucose?',\n",
    "    },\n",
    "    'v3_semantic_qa': {\n",
    "        'search_em': v3_search_em,\n",
    "        'graph_recall': v3_graph_recall,\n",
    "        'use_case': 'Multi-hop reasoning (different entities, semantic relations)',\n",
    "        'example': 'What pathway does glucose participate in?',\n",
    "    },\n",
    "}\n",
    "\n",
    "print(f\"\\nVocabulary QA (v2):\")\n",
    "print(f\"  Method: {comparison['v2_vocabulary_qa']['method']}\")\n",
    "print(f\"  Exact Match: {100*comparison['v2_vocabulary_qa']['exact_match']:.1f}%\")\n",
    "print(f\"  Use case: {comparison['v2_vocabulary_qa']['use_case']}\")\n",
    "print(f\"  Example: {comparison['v2_vocabulary_qa']['example']}\")\n",
    "\n",
    "print(f\"\\nSemantic QA (v3):\")\n",
    "print(f\"  Search EM: {100*comparison['v3_semantic_qa']['search_em']:.1f}%\")\n",
    "print(f\"  Graph Recall: {100*comparison['v3_semantic_qa']['graph_recall']:.1f}%\")\n",
    "print(f\"  Use case: {comparison['v3_semantic_qa']['use_case']}\")\n",
    "print(f\"  Example: {comparison['v3_semantic_qa']['example']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Key Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T01:08:40.683947Z",
     "iopub.status.busy": "2026-01-22T01:08:40.683852Z",
     "iopub.status.idle": "2026-01-22T01:08:40.707940Z",
     "shell.execute_reply": "2026-01-22T01:08:40.706782Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "KEY INSIGHTS\n",
      "============================================================\n",
      "\n",
      "1. Search performs worse on semantic QA\n",
      "   Detail: Search EM drops from 95.2% (vocabulary) to 0.0% (semantic) - a 95.2pp decrease\n",
      "   Implication: Search is optimized for entity resolution, not semantic reasoning\n",
      "\n",
      "2. Graph traversal provides semantic capability\n",
      "   Detail: Graph recall of 63.2% on semantic QA\n",
      "   Implication: KRAKEN has semantic relations accessible via /one-hop\n",
      "\n",
      "3. Complementary use cases\n",
      "   Detail: Search excels at entity resolution; graph traversal for semantic reasoning\n",
      "   Implication: Hybrid approach recommended: search for entities, graph for relations\n"
     ]
    }
   ],
   "source": [
    "# Generate insights\n",
    "print(\"=\"*60)\n",
    "print(\"KEY INSIGHTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "insights = []\n",
    "\n",
    "# Insight 1: Search performance on semantic QA\n",
    "if v3_search_em < v2_vocab_em:\n",
    "    diff = v2_vocab_em - v3_search_em\n",
    "    insights.append({\n",
    "        'finding': 'Search performs worse on semantic QA',\n",
    "        'detail': f'Search EM drops from {100*v2_vocab_em:.1f}% (vocabulary) to {100*v3_search_em:.1f}% (semantic) - a {100*diff:.1f}pp decrease',\n",
    "        'implication': 'Search is optimized for entity resolution, not semantic reasoning',\n",
    "    })\n",
    "\n",
    "# Insight 2: Graph traversal capability\n",
    "if v3_graph_recall > 0:\n",
    "    insights.append({\n",
    "        'finding': 'Graph traversal provides semantic capability',\n",
    "        'detail': f'Graph recall of {100*v3_graph_recall:.1f}% on semantic QA',\n",
    "        'implication': 'KRAKEN has semantic relations accessible via /one-hop',\n",
    "    })\n",
    "else:\n",
    "    insights.append({\n",
    "        'finding': 'Limited graph traversal capability',\n",
    "        'detail': 'Graph traversal did not find answers effectively',\n",
    "        'implication': 'KRAKEN may be primarily vocabulary-focused',\n",
    "    })\n",
    "\n",
    "# Insight 3: Complementary approaches\n",
    "if v3_search_em > 0 or v3_graph_recall > 0:\n",
    "    insights.append({\n",
    "        'finding': 'Complementary use cases',\n",
    "        'detail': 'Search excels at entity resolution; graph traversal for semantic reasoning',\n",
    "        'implication': 'Hybrid approach recommended: search for entities, graph for relations',\n",
    "    })\n",
    "\n",
    "# Display insights\n",
    "for i, insight in enumerate(insights, 1):\n",
    "    print(f\"\\n{i}. {insight['finding']}\")\n",
    "    print(f\"   Detail: {insight['detail']}\")\n",
    "    print(f\"   Implication: {insight['implication']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Semantic Gap Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T01:08:40.710070Z",
     "iopub.status.busy": "2026-01-22T01:08:40.709877Z",
     "iopub.status.idle": "2026-01-22T01:08:40.731282Z",
     "shell.execute_reply": "2026-01-22T01:08:40.730293Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SEMANTIC GAP ASSESSMENT\n",
      "============================================================\n",
      "\n",
      "Predicate Analysis:\n",
      "  Semantic predicates: 26\n",
      "  Equivalency predicates: 1\n",
      "  Semantic edge %: 89.1%\n",
      "\n",
      "Capability Level: HIGH\n",
      "Assessment: KRAKEN has robust semantic capability\n",
      "\n",
      "v2 Conclusion: KRAKEN is vocabulary-focused (v2 achieved 95.2% EM on entity resolution)\n",
      "v3 Finding: Semantic capability is HIGH\n"
     ]
    }
   ],
   "source": [
    "# Semantic gap assessment\n",
    "print(\"=\"*60)\n",
    "print(\"SEMANTIC GAP ASSESSMENT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get predicate data\n",
    "semantic_predicates = 0\n",
    "equiv_predicates = 0\n",
    "semantic_edge_pct = 0\n",
    "\n",
    "if 'predicate_mapping' in v3_results:\n",
    "    summary = v3_results['predicate_mapping'].get('summary', {})\n",
    "    semantic_predicates = summary.get('semantic_predicates', 0)\n",
    "    equiv_predicates = summary.get('equivalency_predicates', 0)\n",
    "    semantic_edge_pct = summary.get('semantic_edge_percent', 0)\n",
    "\n",
    "# Determine semantic capability level\n",
    "if semantic_edge_pct > 50:\n",
    "    capability_level = 'HIGH'\n",
    "    capability_desc = 'KRAKEN has robust semantic capability'\n",
    "elif semantic_edge_pct > 20:\n",
    "    capability_level = 'MEDIUM'\n",
    "    capability_desc = 'KRAKEN has moderate semantic capability'\n",
    "elif semantic_edge_pct > 5:\n",
    "    capability_level = 'LOW'\n",
    "    capability_desc = 'KRAKEN has limited semantic capability'\n",
    "else:\n",
    "    capability_level = 'MINIMAL'\n",
    "    capability_desc = 'KRAKEN is primarily vocabulary-focused'\n",
    "\n",
    "semantic_gap_assessment = {\n",
    "    'semantic_predicates': semantic_predicates,\n",
    "    'equivalency_predicates': equiv_predicates,\n",
    "    'semantic_edge_percent': semantic_edge_pct,\n",
    "    'capability_level': capability_level,\n",
    "    'capability_description': capability_desc,\n",
    "    'v2_conclusion': 'KRAKEN is vocabulary-focused (v2 achieved 95.2% EM on entity resolution)',\n",
    "    'v3_finding': f'Semantic capability is {capability_level}',\n",
    "}\n",
    "\n",
    "print(f\"\\nPredicate Analysis:\")\n",
    "print(f\"  Semantic predicates: {semantic_predicates}\")\n",
    "print(f\"  Equivalency predicates: {equiv_predicates}\")\n",
    "print(f\"  Semantic edge %: {semantic_edge_pct:.1f}%\")\n",
    "print(f\"\\nCapability Level: {capability_level}\")\n",
    "print(f\"Assessment: {capability_desc}\")\n",
    "print(f\"\\nv2 Conclusion: {semantic_gap_assessment['v2_conclusion']}\")\n",
    "print(f\"v3 Finding: {semantic_gap_assessment['v3_finding']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T01:08:40.732772Z",
     "iopub.status.busy": "2026-01-22T01:08:40.732694Z",
     "iopub.status.idle": "2026-01-22T01:08:40.756526Z",
     "shell.execute_reply": "2026-01-22T01:08:40.755265Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RECOMMENDATIONS\n",
      "============================================================\n",
      "\n",
      "1. Entity Resolution\n",
      "   Method: Hybrid Search + Reranking\n",
      "   Expected: 95% EM\n",
      "   Rationale: Search is optimized for finding same entity across vocabularies\n",
      "\n",
      "2. Semantic Queries (pathways, diseases, etc.)\n",
      "   Method: Graph Traversal via /one-hop\n",
      "   Expected: 63% Recall\n",
      "   Rationale: Graph traversal follows semantic edges directly\n",
      "\n",
      "3. Complex Queries\n",
      "   Method: Search + Graph Hybrid\n",
      "   Expected: Depends on query type\n",
      "   Rationale: Use search to find entity, then graph to explore relations\n"
     ]
    }
   ],
   "source": [
    "# Generate recommendations\n",
    "print(\"=\"*60)\n",
    "print(\"RECOMMENDATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "recommendations = []\n",
    "\n",
    "# Recommendation 1: Entity resolution\n",
    "recommendations.append({\n",
    "    'use_case': 'Entity Resolution',\n",
    "    'recommended_method': 'Hybrid Search + Reranking',\n",
    "    'expected_performance': f'{100*v2_vocab_em:.0f}% EM',\n",
    "    'rationale': 'Search is optimized for finding same entity across vocabularies',\n",
    "})\n",
    "\n",
    "# Recommendation 2: Semantic queries\n",
    "if capability_level in ['HIGH', 'MEDIUM']:\n",
    "    recommendations.append({\n",
    "        'use_case': 'Semantic Queries (pathways, diseases, etc.)',\n",
    "        'recommended_method': 'Graph Traversal via /one-hop',\n",
    "        'expected_performance': f'{100*v3_graph_recall:.0f}% Recall',\n",
    "        'rationale': 'Graph traversal follows semantic edges directly',\n",
    "    })\n",
    "else:\n",
    "    recommendations.append({\n",
    "        'use_case': 'Semantic Queries',\n",
    "        'recommended_method': 'External APIs (Reactome, KEGG)',\n",
    "        'expected_performance': 'Varies by API',\n",
    "        'rationale': 'KRAKEN has limited semantic relations',\n",
    "    })\n",
    "\n",
    "# Recommendation 3: Hybrid approach\n",
    "recommendations.append({\n",
    "    'use_case': 'Complex Queries',\n",
    "    'recommended_method': 'Search + Graph Hybrid',\n",
    "    'expected_performance': 'Depends on query type',\n",
    "    'rationale': 'Use search to find entity, then graph to explore relations',\n",
    "})\n",
    "\n",
    "for i, rec in enumerate(recommendations, 1):\n",
    "    print(f\"\\n{i}. {rec['use_case']}\")\n",
    "    print(f\"   Method: {rec['recommended_method']}\")\n",
    "    print(f\"   Expected: {rec['expected_performance']}\")\n",
    "    print(f\"   Rationale: {rec['rationale']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Gap Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T01:08:40.760244Z",
     "iopub.status.busy": "2026-01-22T01:08:40.759832Z",
     "iopub.status.idle": "2026-01-22T01:08:40.783768Z",
     "shell.execute_reply": "2026-01-22T01:08:40.782083Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gap analysis saved to: /home/trentleslie/Insync/projects/biomapper2/notebooks/kg_o1_v3/outputs/semantic_gap_analysis_v3.json\n"
     ]
    }
   ],
   "source": [
    "# Save gap analysis\n",
    "output_data = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'capability_comparison': comparison,\n",
    "    'semantic_gap_assessment': semantic_gap_assessment,\n",
    "    'insights': insights,\n",
    "    'recommendations': recommendations,\n",
    "    'conclusion': {\n",
    "        'search_best_for': 'Entity resolution (vocabulary QA)',\n",
    "        'graph_best_for': 'Semantic reasoning (pathway/disease queries)',\n",
    "        'overall': capability_desc,\n",
    "    },\n",
    "}\n",
    "\n",
    "save_json(output_data, OUTPUT_DIR / 'semantic_gap_analysis_v3.json')\n",
    "print(f\"\\nGap analysis saved to: {OUTPUT_DIR / 'semantic_gap_analysis_v3.json'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T01:08:40.787461Z",
     "iopub.status.busy": "2026-01-22T01:08:40.787146Z",
     "iopub.status.idle": "2026-01-22T01:08:40.815244Z",
     "shell.execute_reply": "2026-01-22T01:08:40.814575Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "NOTEBOOK 07 COMPLETE\n",
      "============================================================\n",
      "\n",
      "Key Findings:\n",
      "  - v2 Vocabulary QA EM: 95.2%\n",
      "  - v3 Semantic Search EM: 0.0%\n",
      "  - v3 Graph Recall: 63.2%\n",
      "  - Semantic Capability: HIGH\n",
      "\n",
      "Conclusion: KRAKEN has robust semantic capability\n",
      "\n",
      "Next step: NB08 - Integration Recommendations\n"
     ]
    }
   ],
   "source": [
    "# Final summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"NOTEBOOK 07 COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nKey Findings:\")\n",
    "print(f\"  - v2 Vocabulary QA EM: {100*v2_vocab_em:.1f}%\")\n",
    "print(f\"  - v3 Semantic Search EM: {100*v3_search_em:.1f}%\")\n",
    "print(f\"  - v3 Graph Recall: {100*v3_graph_recall:.1f}%\")\n",
    "print(f\"  - Semantic Capability: {capability_level}\")\n",
    "\n",
    "print(f\"\\nConclusion: {capability_desc}\")\n",
    "\n",
    "print(f\"\\nNext step: NB08 - Integration Recommendations\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biomapper2 (uv)",
   "language": "python",
   "name": "biomapper2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
