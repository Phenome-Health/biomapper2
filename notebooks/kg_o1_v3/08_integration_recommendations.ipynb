{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 08: Integration Recommendations\n",
    "\n",
    "## Objective\n",
    "\n",
    "Provide actionable production recommendations for biomapper2 based on v3 findings.\n",
    "\n",
    "## Key Deliverables\n",
    "\n",
    "1. Production-ready `/one-hop` wrapper functions\n",
    "2. When to use search vs graph traversal\n",
    "3. Hybrid approach implementation guide\n",
    "4. API integration code snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T00:45:55.819244Z",
     "iopub.status.busy": "2026-01-22T00:45:55.819164Z",
     "iopub.status.idle": "2026-01-22T00:45:56.073257Z",
     "shell.execute_reply": "2026-01-22T00:45:56.072857Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /home/trentleslie/Insync/projects/biomapper2\n",
      "Output directory: /home/trentleslie/Insync/projects/biomapper2/notebooks/kg_o1_v3/outputs\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Add project root to path\n",
    "PROJECT_ROOT = Path.cwd().parents[1]\n",
    "sys.path.insert(0, str(PROJECT_ROOT / 'src'))\n",
    "sys.path.insert(0, str(Path.cwd()))\n",
    "\n",
    "# Import utilities\n",
    "from kg_o1_v3_utils import save_json, load_json\n",
    "\n",
    "# Output directory\n",
    "OUTPUT_DIR = Path.cwd() / 'outputs'\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load v3 Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T00:45:56.097657Z",
     "iopub.status.busy": "2026-01-22T00:45:56.097352Z",
     "iopub.status.idle": "2026-01-22T00:45:56.100014Z",
     "shell.execute_reply": "2026-01-22T00:45:56.099659Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded gap analysis from NB07\n",
      "Semantic capability level: MINIMAL\n"
     ]
    }
   ],
   "source": [
    "# Load gap analysis from NB07\n",
    "if (OUTPUT_DIR / 'semantic_gap_analysis_v3.json').exists():\n",
    "    gap_analysis = load_json(OUTPUT_DIR / 'semantic_gap_analysis_v3.json')\n",
    "    print(\"Loaded gap analysis from NB07\")\n",
    "    \n",
    "    capability_level = gap_analysis.get('semantic_gap_assessment', {}).get('capability_level', 'UNKNOWN')\n",
    "    print(f\"Semantic capability level: {capability_level}\")\n",
    "else:\n",
    "    print(\"WARNING: Gap analysis not found. Using defaults.\")\n",
    "    gap_analysis = {}\n",
    "    capability_level = 'UNKNOWN'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Production-Ready One-Hop Wrapper\n",
    "\n",
    "Here's the code to add to biomapper2 for semantic graph traversal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T00:45:56.101037Z",
     "iopub.status.busy": "2026-01-22T00:45:56.100961Z",
     "iopub.status.idle": "2026-01-22T00:45:56.120390Z",
     "shell.execute_reply": "2026-01-22T00:45:56.119774Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Production One-Hop Wrapper Code:\n",
      "============================================================\n",
      "\n",
      "\"\"\"One-hop graph traversal for semantic queries.\"\"\"\n",
      "\n",
      "from typing import Optional\n",
      "from biomapper2.utils import kestrel_request\n",
      "\n",
      "\n",
      "def get_semantic_relations(\n",
      "    entity_id: str,\n",
      "    direction: str = \"both\",\n",
      "    predicate_filter: Optional[str] = None,\n",
      "    category_filter: Optional[str] = None,\n",
      "    limit: int = 50,\n",
      ") -> list[dict]:\n",
      "    \"\"\"\n",
      "    Get semantic relations for an entity via one-hop traversal.\n",
      "\n",
      "    Use this for semantic queries like:\n",
      "    - \"What pathways does X participate in?\"\n",
      "    - \"What diseases are associated with X?\"\n",
      "    - \"What genes interact with X?\"\n",
      "\n",
      "    For entity resolution (vocabulary mapping), use hybrid_search instead.\n",
      "\n",
      "    Args:\n",
      "        entity_id: Entity ID (e.g., \"CHEBI:4167\")\n",
      "        direction: \"forward\", \"reverse\", or \"both\"\n",
      "        predicate_filter: Filter by predicate (e.g., \"participates_in\")\n",
      "        category_filter: Filter by end category (e.g., \"Pathway\")\n",
      "        limit: Maximum results\n",
      "\n",
      "    Returns:\n",
      "        List of relation dictionaries with predicate, object_id, object_name\n",
      "    \"\"\"\n",
      "    payload = {\n",
      "        \"start_node_ids\": entity_id,\n",
      "        \"direction\": direction,\n",
      "        \"limit\": limit,\n",
      "        \"mode\": \"slim\",\n",
      "    }\n",
      "\n",
      "    if predicate_filter:\n",
      "        payload[\"predicate_filter\"] = predicate_filter\n",
      "    if category_filter:\n",
      "        payload[\"end_category_filter\"] = category_filter\n",
      "\n",
      "    try:\n",
      "        response = kestrel_request(\"POST\", \"one-hop\", json=payload)\n",
      "\n",
      "        if isinstance(response, list):\n",
      "            return response\n",
      "        elif isinstance(response, dict) and \"error\" not in response:\n",
      "            return response.get(\"edges\", response.get(\"results\", []))\n",
      "        return []\n",
      "\n",
      "    except Exception:\n",
      "        return []\n",
      "\n",
      "\n",
      "def get_pathways_for_entity(entity_id: str, limit: int = 20) -> list[dict]:\n",
      "    \"\"\"Convenience function to get pathways for a metabolite.\"\"\"\n",
      "    return get_semantic_relations(\n",
      "        entity_id,\n",
      "        direction=\"forward\",\n",
      "        predicate_filter=\"participates_in\",\n",
      "        category_filter=\"Pathway\",\n",
      "        limit=limit,\n",
      "    )\n",
      "\n",
      "\n",
      "def get_associated_diseases(entity_id: str, limit: int = 20) -> list[dict]:\n",
      "    \"\"\"Convenience function to get diseases associated with an entity.\"\"\"\n",
      "    return get_semantic_relations(\n",
      "        entity_id,\n",
      "        direction=\"both\",\n",
      "        predicate_filter=\"associated_with\",\n",
      "        category_filter=\"Disease\",\n",
      "        limit=limit,\n",
      "    )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Production one-hop wrapper code\n",
    "one_hop_wrapper_code = '''\n",
    "\"\"\"One-hop graph traversal for semantic queries.\"\"\"\n",
    "\n",
    "from typing import Optional\n",
    "from biomapper2.utils import kestrel_request\n",
    "\n",
    "\n",
    "def get_semantic_relations(\n",
    "    entity_id: str,\n",
    "    direction: str = \"both\",\n",
    "    predicate_filter: Optional[str] = None,\n",
    "    category_filter: Optional[str] = None,\n",
    "    limit: int = 50,\n",
    ") -> list[dict]:\n",
    "    \"\"\"\n",
    "    Get semantic relations for an entity via one-hop traversal.\n",
    "    \n",
    "    Use this for semantic queries like:\n",
    "    - \"What pathways does X participate in?\"\n",
    "    - \"What diseases are associated with X?\"\n",
    "    - \"What genes interact with X?\"\n",
    "    \n",
    "    For entity resolution (vocabulary mapping), use hybrid_search instead.\n",
    "    \n",
    "    Args:\n",
    "        entity_id: Entity ID (e.g., \"CHEBI:4167\")\n",
    "        direction: \"forward\", \"reverse\", or \"both\"\n",
    "        predicate_filter: Filter by predicate (e.g., \"participates_in\")\n",
    "        category_filter: Filter by end category (e.g., \"Pathway\")\n",
    "        limit: Maximum results\n",
    "    \n",
    "    Returns:\n",
    "        List of relation dictionaries with predicate, object_id, object_name\n",
    "    \"\"\"\n",
    "    payload = {\n",
    "        \"start_node_ids\": entity_id,\n",
    "        \"direction\": direction,\n",
    "        \"limit\": limit,\n",
    "        \"mode\": \"slim\",\n",
    "    }\n",
    "    \n",
    "    if predicate_filter:\n",
    "        payload[\"predicate_filter\"] = predicate_filter\n",
    "    if category_filter:\n",
    "        payload[\"end_category_filter\"] = category_filter\n",
    "    \n",
    "    try:\n",
    "        response = kestrel_request(\"POST\", \"one-hop\", json=payload)\n",
    "        \n",
    "        if isinstance(response, list):\n",
    "            return response\n",
    "        elif isinstance(response, dict) and \"error\" not in response:\n",
    "            return response.get(\"edges\", response.get(\"results\", []))\n",
    "        return []\n",
    "        \n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "\n",
    "def get_pathways_for_entity(entity_id: str, limit: int = 20) -> list[dict]:\n",
    "    \"\"\"Convenience function to get pathways for a metabolite.\"\"\"\n",
    "    return get_semantic_relations(\n",
    "        entity_id,\n",
    "        direction=\"forward\",\n",
    "        predicate_filter=\"participates_in\",\n",
    "        category_filter=\"Pathway\",\n",
    "        limit=limit,\n",
    "    )\n",
    "\n",
    "\n",
    "def get_associated_diseases(entity_id: str, limit: int = 20) -> list[dict]:\n",
    "    \"\"\"Convenience function to get diseases associated with an entity.\"\"\"\n",
    "    return get_semantic_relations(\n",
    "        entity_id,\n",
    "        direction=\"both\",\n",
    "        predicate_filter=\"associated_with\",\n",
    "        category_filter=\"Disease\",\n",
    "        limit=limit,\n",
    "    )\n",
    "'''\n",
    "\n",
    "print(\"Production One-Hop Wrapper Code:\")\n",
    "print(\"=\"*60)\n",
    "print(one_hop_wrapper_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. When to Use Each Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T00:45:56.122331Z",
     "iopub.status.busy": "2026-01-22T00:45:56.122151Z",
     "iopub.status.idle": "2026-01-22T00:45:56.156184Z",
     "shell.execute_reply": "2026-01-22T00:45:56.155215Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METHOD SELECTION GUIDE\n",
      "============================================================\n",
      "\n",
      "ENTITY_RESOLUTION\n",
      "----------------------------------------\n",
      "Description: Finding the same entity across different vocabulary IDs\n",
      "\n",
      "Examples:\n",
      "  - What is the HMDB ID for glucose?\n",
      "  - Map CHEBI:4167 to KEGG\n",
      "  - Find DRUGBANK equivalents for this compound\n",
      "\n",
      "Method: hybrid_search + reranking\n",
      "Performance: 95%+ EM\n",
      "\n",
      "Code:\n",
      "  hybrid_search(\"glucose\", limit=10)\n",
      "\n",
      "SEMANTIC_1_HOP\n",
      "----------------------------------------\n",
      "Description: Finding entities related by semantic predicates\n",
      "\n",
      "Examples:\n",
      "  - What pathways does glucose participate in?\n",
      "  - What diseases are associated with cholesterol?\n",
      "  - What genes are affected by this drug?\n",
      "\n",
      "Method: get_semantic_relations() via one-hop\n",
      "Performance: Varies by predicate coverage\n",
      "\n",
      "Code:\n",
      "  get_semantic_relations(\"CHEBI:4167\", predicate_filter=\"participates_in\")\n",
      "\n",
      "SEMANTIC_MULTI_HOP\n",
      "----------------------------------------\n",
      "Description: Finding connections through multiple semantic hops\n",
      "\n",
      "Examples:\n",
      "  - How is glucose connected to diabetes?\n",
      "  - What pathways link these two metabolites?\n",
      "\n",
      "Method: BFS path finding with safeguards\n",
      "Performance: Depends on graph connectivity\n",
      "\n",
      "Code:\n",
      "  find_path_bfs(start_id, end_id, max_hops=3, semantic_only=True)\n",
      "\n",
      "HYBRID_QUERY\n",
      "----------------------------------------\n",
      "Description: Complex queries requiring both entity resolution and semantic traversal\n",
      "\n",
      "Examples:\n",
      "  - Find pathways for \"vitamin B12\" (need to resolve name first)\n",
      "  - Get disease associations for metabolites in my dataset\n",
      "\n",
      "Method: Search first, then graph traversal\n",
      "Performance: Compound accuracy\n",
      "\n",
      "Code:\n",
      "  # Step 1: Resolve entity\n",
      "results = hybrid_search(\"vitamin B12\")\n",
      "entity_id = results[0][\"id\"]\n",
      "\n",
      "# Step 2: Get semantic relations\n",
      "pathways = get_pathways_for_entity(entity_id)\n"
     ]
    }
   ],
   "source": [
    "# Decision tree for method selection\n",
    "decision_tree = {\n",
    "    'entity_resolution': {\n",
    "        'description': 'Finding the same entity across different vocabulary IDs',\n",
    "        'examples': [\n",
    "            'What is the HMDB ID for glucose?',\n",
    "            'Map CHEBI:4167 to KEGG',\n",
    "            'Find DRUGBANK equivalents for this compound',\n",
    "        ],\n",
    "        'recommended_method': 'hybrid_search + reranking',\n",
    "        'expected_performance': '95%+ EM',\n",
    "        'code_snippet': 'hybrid_search(\"glucose\", limit=10)',\n",
    "    },\n",
    "    'semantic_1_hop': {\n",
    "        'description': 'Finding entities related by semantic predicates',\n",
    "        'examples': [\n",
    "            'What pathways does glucose participate in?',\n",
    "            'What diseases are associated with cholesterol?',\n",
    "            'What genes are affected by this drug?',\n",
    "        ],\n",
    "        'recommended_method': 'get_semantic_relations() via one-hop',\n",
    "        'expected_performance': 'Varies by predicate coverage',\n",
    "        'code_snippet': 'get_semantic_relations(\"CHEBI:4167\", predicate_filter=\"participates_in\")',\n",
    "    },\n",
    "    'semantic_multi_hop': {\n",
    "        'description': 'Finding connections through multiple semantic hops',\n",
    "        'examples': [\n",
    "            'How is glucose connected to diabetes?',\n",
    "            'What pathways link these two metabolites?',\n",
    "        ],\n",
    "        'recommended_method': 'BFS path finding with safeguards',\n",
    "        'expected_performance': 'Depends on graph connectivity',\n",
    "        'code_snippet': 'find_path_bfs(start_id, end_id, max_hops=3, semantic_only=True)',\n",
    "    },\n",
    "    'hybrid_query': {\n",
    "        'description': 'Complex queries requiring both entity resolution and semantic traversal',\n",
    "        'examples': [\n",
    "            'Find pathways for \"vitamin B12\" (need to resolve name first)',\n",
    "            'Get disease associations for metabolites in my dataset',\n",
    "        ],\n",
    "        'recommended_method': 'Search first, then graph traversal',\n",
    "        'expected_performance': 'Compound accuracy',\n",
    "        'code_snippet': '''# Step 1: Resolve entity\\nresults = hybrid_search(\"vitamin B12\")\\nentity_id = results[0][\"id\"]\\n\\n# Step 2: Get semantic relations\\npathways = get_pathways_for_entity(entity_id)''',\n",
    "    },\n",
    "}\n",
    "\n",
    "print(\"METHOD SELECTION GUIDE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for query_type, info in decision_tree.items():\n",
    "    print(f\"\\n{query_type.upper()}\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Description: {info['description']}\")\n",
    "    print(f\"\\nExamples:\")\n",
    "    for ex in info['examples']:\n",
    "        print(f\"  - {ex}\")\n",
    "    print(f\"\\nMethod: {info['recommended_method']}\")\n",
    "    print(f\"Performance: {info['expected_performance']}\")\n",
    "    print(f\"\\nCode:\")\n",
    "    print(f\"  {info['code_snippet']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hybrid Query Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T00:45:56.158206Z",
     "iopub.status.busy": "2026-01-22T00:45:56.157899Z",
     "iopub.status.idle": "2026-01-22T00:45:56.185750Z",
     "shell.execute_reply": "2026-01-22T00:45:56.184856Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Query Implementation:\n",
      "============================================================\n",
      "\n",
      "\"\"\"Hybrid query implementation combining search and graph traversal.\"\"\"\n",
      "\n",
      "from typing import Optional\n",
      "\n",
      "\n",
      "def query_with_semantic_expansion(\n",
      "    query: str,\n",
      "    predicates: Optional[list[str]] = None,\n",
      "    search_limit: int = 5,\n",
      "    relation_limit: int = 20,\n",
      ") -> dict:\n",
      "    \"\"\"\n",
      "    Execute a hybrid query: search for entity, then expand semantically.\n",
      "\n",
      "    Args:\n",
      "        query: Natural language query or entity name\n",
      "        predicates: Predicates to expand (default: participates_in, associated_with)\n",
      "        search_limit: Max entities to consider from search\n",
      "        relation_limit: Max relations per entity\n",
      "\n",
      "    Returns:\n",
      "        Dict with resolved_entities and their semantic_relations\n",
      "    \"\"\"\n",
      "    if predicates is None:\n",
      "        predicates = [\"participates_in\", \"associated_with\", \"affects\"]\n",
      "\n",
      "    # Step 1: Resolve entity via search\n",
      "    search_results = hybrid_search(query, limit=search_limit)\n",
      "\n",
      "    if not search_results:\n",
      "        return {\"resolved_entities\": [], \"semantic_relations\": []}\n",
      "\n",
      "    # Step 2: Get semantic relations for top entities\n",
      "    all_relations = []\n",
      "\n",
      "    for entity in search_results[:search_limit]:\n",
      "        entity_id = entity.get(\"id\")\n",
      "        entity_name = entity.get(\"name\", entity_id)\n",
      "\n",
      "        for predicate in predicates:\n",
      "            relations = get_semantic_relations(\n",
      "                entity_id,\n",
      "                predicate_filter=predicate,\n",
      "                limit=relation_limit,\n",
      "            )\n",
      "\n",
      "            for rel in relations:\n",
      "                all_relations.append({\n",
      "                    \"source_entity\": entity_name,\n",
      "                    \"source_id\": entity_id,\n",
      "                    \"predicate\": predicate,\n",
      "                    \"target_entity\": rel.get(\"object_name\", rel.get(\"end_node_name\")),\n",
      "                    \"target_id\": rel.get(\"object_id\", rel.get(\"end_node_id\")),\n",
      "                    \"target_category\": rel.get(\"object_category\", rel.get(\"category\")),\n",
      "                })\n",
      "\n",
      "    return {\n",
      "        \"resolved_entities\": search_results[:search_limit],\n",
      "        \"semantic_relations\": all_relations,\n",
      "    }\n",
      "\n",
      "\n",
      "# Example usage:\n",
      "# result = query_with_semantic_expansion(\n",
      "#     \"glucose\",\n",
      "#     predicates=[\"participates_in\", \"affects\"],\n",
      "# )\n",
      "# print(f\"Found {len(result['semantic_relations'])} relations\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hybrid query implementation code\n",
    "hybrid_query_code = '''\n",
    "\"\"\"Hybrid query implementation combining search and graph traversal.\"\"\"\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "def query_with_semantic_expansion(\n",
    "    query: str,\n",
    "    predicates: Optional[list[str]] = None,\n",
    "    search_limit: int = 5,\n",
    "    relation_limit: int = 20,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Execute a hybrid query: search for entity, then expand semantically.\n",
    "    \n",
    "    Args:\n",
    "        query: Natural language query or entity name\n",
    "        predicates: Predicates to expand (default: participates_in, associated_with)\n",
    "        search_limit: Max entities to consider from search\n",
    "        relation_limit: Max relations per entity\n",
    "    \n",
    "    Returns:\n",
    "        Dict with resolved_entities and their semantic_relations\n",
    "    \"\"\"\n",
    "    if predicates is None:\n",
    "        predicates = [\"participates_in\", \"associated_with\", \"affects\"]\n",
    "    \n",
    "    # Step 1: Resolve entity via search\n",
    "    search_results = hybrid_search(query, limit=search_limit)\n",
    "    \n",
    "    if not search_results:\n",
    "        return {\"resolved_entities\": [], \"semantic_relations\": []}\n",
    "    \n",
    "    # Step 2: Get semantic relations for top entities\n",
    "    all_relations = []\n",
    "    \n",
    "    for entity in search_results[:search_limit]:\n",
    "        entity_id = entity.get(\"id\")\n",
    "        entity_name = entity.get(\"name\", entity_id)\n",
    "        \n",
    "        for predicate in predicates:\n",
    "            relations = get_semantic_relations(\n",
    "                entity_id,\n",
    "                predicate_filter=predicate,\n",
    "                limit=relation_limit,\n",
    "            )\n",
    "            \n",
    "            for rel in relations:\n",
    "                all_relations.append({\n",
    "                    \"source_entity\": entity_name,\n",
    "                    \"source_id\": entity_id,\n",
    "                    \"predicate\": predicate,\n",
    "                    \"target_entity\": rel.get(\"object_name\", rel.get(\"end_node_name\")),\n",
    "                    \"target_id\": rel.get(\"object_id\", rel.get(\"end_node_id\")),\n",
    "                    \"target_category\": rel.get(\"object_category\", rel.get(\"category\")),\n",
    "                })\n",
    "    \n",
    "    return {\n",
    "        \"resolved_entities\": search_results[:search_limit],\n",
    "        \"semantic_relations\": all_relations,\n",
    "    }\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# result = query_with_semantic_expansion(\n",
    "#     \"glucose\",\n",
    "#     predicates=[\"participates_in\", \"affects\"],\n",
    "# )\n",
    "# print(f\"Found {len(result[\\'semantic_relations\\'])} relations\")\n",
    "'''\n",
    "\n",
    "print(\"Hybrid Query Implementation:\")\n",
    "print(\"=\"*60)\n",
    "print(hybrid_query_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Integration Checklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T00:45:56.187452Z",
     "iopub.status.busy": "2026-01-22T00:45:56.187237Z",
     "iopub.status.idle": "2026-01-22T00:45:56.210123Z",
     "shell.execute_reply": "2026-01-22T00:45:56.209509Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTEGRATION CHECKLIST\n",
      "============================================================\n",
      "\n",
      "[!] Add one-hop wrapper to biomapper2\n",
      "    File: src/biomapper2/core/semantic_query.py\n",
      "    Priority: HIGH\n",
      "\n",
      "[!] Add hybrid query function\n",
      "    File: src/biomapper2/core/semantic_query.py\n",
      "    Priority: HIGH\n",
      "\n",
      "[-] Add convenience functions (get_pathways, get_diseases)\n",
      "    File: src/biomapper2/core/semantic_query.py\n",
      "    Priority: MEDIUM\n",
      "\n",
      "[ ] Add BFS path finding with safeguards\n",
      "    File: src/biomapper2/core/path_finder.py\n",
      "    Priority: LOW\n",
      "\n",
      "[-] Update Mapper class with semantic query methods\n",
      "    File: src/biomapper2/mapper.py\n",
      "    Priority: MEDIUM\n",
      "\n",
      "[!] Add tests for semantic queries\n",
      "    File: tests/test_semantic_query.py\n",
      "    Priority: HIGH\n",
      "\n",
      "[ ] Document semantic query capabilities\n",
      "    File: docs/semantic_queries.md\n",
      "    Priority: LOW\n"
     ]
    }
   ],
   "source": [
    "# Integration checklist\n",
    "integration_checklist = [\n",
    "    {\n",
    "        'task': 'Add one-hop wrapper to biomapper2',\n",
    "        'file': 'src/biomapper2/core/semantic_query.py',\n",
    "        'priority': 'HIGH',\n",
    "        'status': 'TODO',\n",
    "    },\n",
    "    {\n",
    "        'task': 'Add hybrid query function',\n",
    "        'file': 'src/biomapper2/core/semantic_query.py',\n",
    "        'priority': 'HIGH',\n",
    "        'status': 'TODO',\n",
    "    },\n",
    "    {\n",
    "        'task': 'Add convenience functions (get_pathways, get_diseases)',\n",
    "        'file': 'src/biomapper2/core/semantic_query.py',\n",
    "        'priority': 'MEDIUM',\n",
    "        'status': 'TODO',\n",
    "    },\n",
    "    {\n",
    "        'task': 'Add BFS path finding with safeguards',\n",
    "        'file': 'src/biomapper2/core/path_finder.py',\n",
    "        'priority': 'LOW',\n",
    "        'status': 'TODO',\n",
    "    },\n",
    "    {\n",
    "        'task': 'Update Mapper class with semantic query methods',\n",
    "        'file': 'src/biomapper2/mapper.py',\n",
    "        'priority': 'MEDIUM',\n",
    "        'status': 'TODO',\n",
    "    },\n",
    "    {\n",
    "        'task': 'Add tests for semantic queries',\n",
    "        'file': 'tests/test_semantic_query.py',\n",
    "        'priority': 'HIGH',\n",
    "        'status': 'TODO',\n",
    "    },\n",
    "    {\n",
    "        'task': 'Document semantic query capabilities',\n",
    "        'file': 'docs/semantic_queries.md',\n",
    "        'priority': 'LOW',\n",
    "        'status': 'TODO',\n",
    "    },\n",
    "]\n",
    "\n",
    "print(\"INTEGRATION CHECKLIST\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for item in integration_checklist:\n",
    "    priority_marker = {'HIGH': '!', 'MEDIUM': '-', 'LOW': ' '}[item['priority']]\n",
    "    print(f\"\\n[{priority_marker}] {item['task']}\")\n",
    "    print(f\"    File: {item['file']}\")\n",
    "    print(f\"    Priority: {item['priority']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Integration Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T00:45:56.211507Z",
     "iopub.status.busy": "2026-01-22T00:45:56.211369Z",
     "iopub.status.idle": "2026-01-22T00:45:56.227392Z",
     "shell.execute_reply": "2026-01-22T00:45:56.227069Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Integration recommendations saved to: /home/trentleslie/Insync/projects/biomapper2/notebooks/kg_o1_v3/outputs/integration_recommendations.json\n"
     ]
    }
   ],
   "source": [
    "# Save integration recommendations\n",
    "output_data = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'v3_capability_level': capability_level,\n",
    "    'decision_tree': decision_tree,\n",
    "    'integration_checklist': integration_checklist,\n",
    "    'code_snippets': {\n",
    "        'one_hop_wrapper': one_hop_wrapper_code,\n",
    "        'hybrid_query': hybrid_query_code,\n",
    "    },\n",
    "    'key_recommendations': [\n",
    "        'Continue using search for entity resolution (95%+ EM)',\n",
    "        'Add one-hop wrapper for semantic queries',\n",
    "        'Implement hybrid approach for complex queries',\n",
    "        'Use BFS with safeguards for multi-hop paths',\n",
    "    ],\n",
    "}\n",
    "\n",
    "save_json(output_data, OUTPUT_DIR / 'integration_recommendations.json')\n",
    "print(f\"\\nIntegration recommendations saved to: {OUTPUT_DIR / 'integration_recommendations.json'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T00:45:56.228160Z",
     "iopub.status.busy": "2026-01-22T00:45:56.228077Z",
     "iopub.status.idle": "2026-01-22T00:45:56.259428Z",
     "shell.execute_reply": "2026-01-22T00:45:56.258663Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "NOTEBOOK 08 COMPLETE - KG-o1 v3 SERIES COMPLETE\n",
      "============================================================\n",
      "\n",
      "v3 Exploration Summary:\n",
      "  - Tested /one-hop endpoint for semantic graph traversal\n",
      "  - Classified predicates as SEMANTIC vs EQUIVALENCY\n",
      "  - Extracted semantic subgraphs with true relations\n",
      "  - Implemented BFS path finding with explosion safeguards\n",
      "  - Generated and validated semantic QA pairs\n",
      "  - Compared search vs graph traversal performance\n",
      "  - Quantified v2 vs v3 capability gap\n",
      "  - Provided production integration recommendations\n",
      "\n",
      "Key Takeaway:\n",
      "  - Search: Best for entity resolution (95% EM)\n",
      "  - Graph: Adds semantic capability (pathways, diseases, etc.)\n",
      "  - Hybrid: Combine both for comprehensive coverage\n",
      "\n",
      "Output files in: /home/trentleslie/Insync/projects/biomapper2/notebooks/kg_o1_v3/outputs\n",
      "\n",
      "Next steps:\n",
      "  1. Review integration checklist\n",
      "  2. Add code to biomapper2\n",
      "  3. Update KG_O1_EXPLORATION_REPORT.md with v3 findings\n"
     ]
    }
   ],
   "source": [
    "# Final summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"NOTEBOOK 08 COMPLETE - KG-o1 v3 SERIES COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nv3 Exploration Summary:\")\n",
    "print(f\"  - Tested /one-hop endpoint for semantic graph traversal\")\n",
    "print(f\"  - Classified predicates as SEMANTIC vs EQUIVALENCY\")\n",
    "print(f\"  - Extracted semantic subgraphs with true relations\")\n",
    "print(f\"  - Implemented BFS path finding with explosion safeguards\")\n",
    "print(f\"  - Generated and validated semantic QA pairs\")\n",
    "print(f\"  - Compared search vs graph traversal performance\")\n",
    "print(f\"  - Quantified v2 vs v3 capability gap\")\n",
    "print(f\"  - Provided production integration recommendations\")\n",
    "\n",
    "print(f\"\\nKey Takeaway:\")\n",
    "print(f\"  - Search: Best for entity resolution ({gap_analysis.get('capability_comparison', {}).get('v2_vocabulary_qa', {}).get('exact_match', 0.952)*100:.0f}% EM)\")\n",
    "print(f\"  - Graph: Adds semantic capability (pathways, diseases, etc.)\")\n",
    "print(f\"  - Hybrid: Combine both for comprehensive coverage\")\n",
    "\n",
    "print(f\"\\nOutput files in: {OUTPUT_DIR}\")\n",
    "print(f\"\\nNext steps:\")\n",
    "print(f\"  1. Review integration checklist\")\n",
    "print(f\"  2. Add code to biomapper2\")\n",
    "print(f\"  3. Update KG_O1_EXPLORATION_REPORT.md with v3 findings\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biomapper2 (uv)",
   "language": "python",
   "name": "biomapper2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
